architecture:
    input: 
        img ~ dicom: [shape = [64,64,64,1]];
    output:
        label ~ flat: [2];

    img 
      -> Conv3D:[16, kernel_size=[3, 3, 3],strides = [2,2,2], padding = 'same',activation='relu']
      -> Conv3D:[16, kernel_size=[3, 3, 3],strides = [2,2,2], padding = 'same',activation='relu']
      -> MaxPooling3D:[pool_size=[2, 2, 2], padding = 'same']
      -> Conv3D:[32, kernel_size=[3, 3, 3], padding = 'same',activation='relu']
      -> Conv3D:[64, kernel_size=[3, 3, 3], padding = 'same', activation='relu']
      -> MaxPooling3D:[pool_size=[2, 2, 2], padding = 'same']
      -> Flatten:[]
      -> Dense:[256, activation='relu']
      -> Dense:[2, activation='softmax']
      -> label;

source:
    bind = "training_data.csv";
    input:
        img ~ from "data"
          -> dicom: [shape = [64, 64, 64, 1]]
          -> DicomDataGenerator:[spacing=[2.0,2.0,2.0],normalise_zero_to_one = True,flip=True];
    output:
      label ~ from "label"
          -> flat: [2]
          -> FlatDataGenerator:[];
    params:
        batch_size = 8,
        shuffle = True,
        shuffle_init = True,
        repeat_per_load=10;

train :
    compile:
        optimizer = Adam:[lr = 0.0001],
        loss = 'categorical_crossentropy',
        metrics = ['accuracy'];
    run:
        epochs = 2;
    dashboard: ;






