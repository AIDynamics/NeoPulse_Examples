architecture:
    input: 
        img ~ image: [shape = [28,28], channels = 1];
    output:
        label ~ flat: [10];

    img 
      -> Conv2D: [filters = 32, kernel_size = 5, strides = 2, padding = 'valid', activation = 'relu', name = 'conv1']
      -> PrimaryCaps_Matrix: []
      -> ConvCaps:[channels = 32, kernel_size = 3, strides = 2, routings = 3]
      -> ConvCaps:[channels = 32, kernel_size = 3, strides = 1, routings = 3]
      -> ClassCaps:[num_capsule = 10, routings = 3]
      -> label;

source:
    bind = "training_data.csv";
    input:
        img ~ from "Image"
          -> image: [shape = [28,28], channels = 1]
          -> ImageDataGenerator:[rescale = 0.00392156862745098];
    output:
      label ~ from "Label"
          -> flat: [10]
          -> FlatDataGenerator:[];
    params:
        batch_size = 64,
        validation_split = 0.2 ;

train :
    compile:
        optimizer = Adam:[lr = 0.001],
        loss = "spreadloss",
        metrics = ['accuracy'];
    run:
        epochs = 2;
    dashboard: ;






